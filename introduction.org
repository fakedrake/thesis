* The START ecosystem

  START (SynTactic Analysis using Reversible Transformations) is a
  system designed to answer questions posed in natural language,
  favoring precision over recall. It was developed by Boris Katz at
  MiT's Artificial Intelligence Laboratory and was connected to the
  internet in December 1993. The basic premise of its functionality
  is that it normalizes questions into internal representations that
  it matches against its knowledge base to present the user with an
  accurate answer. Currently START is developed and maintained by
  InfoLab, led by Boris Katz.

  START's fundamental element of meaning is a recursive structure
  called ternary expression or T-expression. It is a tuple of 3
  elements containing a subject, a relation and an object; each of
  which may be either a symbol (eg =John loves cake= would become
  =(JOHN LOVE CAKE-1)=) or another T-expression (eg =Bill thinks that
  John loves Mary's daughter= becomes =[Bill think [John love
  daughter-1]] [daughter-1 related-to Mary]=). START focuses on
  transforming information between natural language and T-expression
  format, and on recognizing semantic relationships between
  T-expressions. This way it can answer natural language questions by
  transforming the question into a T-expression, matching it against
  a knowledge base of T-expressions to come up with a T-expression
  answer that it finally transforms into a textual answer.

  However it is not always the case that a dataset can be trivially
  transformed into T-expressions, either because the text is too
  complex to parse, or because the data is in another format like
  image, sound, video, tables etc. To overcome this limitation START
  introduces the concept of a schema as a method to annotate
  arbitrary data with T-expressions in order to gain access to
  them. While the actual schema implementation is much more complex,
  a schema is essentially a pair of two components:

  - a set of T-expressions, the =annotations=, that are matched
    against the query T-expressions,
  - and a method of generating data given a =T-expression= that
    matches the schema's =annotations=. While this method will
    typically use slightly modified data, either fetched from the
    internet or even hardcoded, there are no restrictions to what data
    a schema can generate.

  For question answering to be of any practical use START needs a way
  to retrieve information from the internet. For that reason InfoLab
  invented omnibase, a "virtual" database that provides a uniform
  interface to multiple Web knowledge sources, capable of executing
  the structured queries generated by START. Omnibase was first
  developed in 2002, at about the same time when wikipedia made its
  first appearance (2001).

  The online encyclopedia Wikipedia is a vast, constantly evolving
  tapestry of richly interlinked textual information.  To a growing
  community of researchers and developers it is an ever-growing source
  of manually defined concepts and semantic relations. It constitutes
  an unparalleled and largely untapped resource for natural language
  processing, knowledge management, data mining, and other research
  areas. It is the product of the collaborative work of millions of
  people. Wikipedia is based on the wiki system, a category of
  websites that allow for collaborative modification of content.

  Due to the complexity and the highly unstructured nature of
  wikipedia instead of an omnibase backend START uses a separate
  service, WikipediaBase, the subject of this thesis. Also to avoid
  blasting =wikidpedia.org= we developed wikipedia mirror to create a
  clone of wikipedia for WikipediaBase to use.
